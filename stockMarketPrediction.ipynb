{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    81288\n",
       " 2    63777\n",
       " 0    41977\n",
       "-2    25351\n",
       " 1    10583\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine sentiment by stanford\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('sentiment_tweet.csv', quotechar='\"')\n",
    "del df['text']\n",
    "del df['Unnamed: 0']\n",
    "del df['Unnamed: 0.1']\n",
    "del df['user']\n",
    "\n",
    "import ast\n",
    "\n",
    "def getSent(row):\n",
    "    sentiment = ast.literal_eval(row['sentiment'])['sentiment']\n",
    "    stanford = row['stanford']\n",
    "    if stanford == 1:\n",
    "        stanford = 1\n",
    "    if stanford == -1:\n",
    "        stanford = -1\n",
    "    if stanford == 2:\n",
    "        stanford = 1\n",
    "    if stanford == -2:\n",
    "        stanford = -1\n",
    "    if sentiment == None:\n",
    "        return stanford\n",
    "    else:\n",
    "        if sentiment['basic'] == 'Bullish':\n",
    "            return 2\n",
    "        if sentiment['basic'] == 'Bearish':\n",
    "            return -2\n",
    "        return stanford\n",
    "    \n",
    "df['sentiment'] = df.apply(getSent, axis=1)\n",
    "del df['stanford']\n",
    "df.head()\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2018.03.16   -0.005629\n",
       "2018.03.17   -0.000658\n",
       "2018.03.18   -0.000340\n",
       "2018.03.19   -0.000106\n",
       "2018.03.20   -0.000543\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregate by date\n",
    "def getIndex(arr):\n",
    "    bull = 0\n",
    "    bear = 0\n",
    "    for i in arr:\n",
    "        if i > 0:\n",
    "            bull += i\n",
    "        if i < 0:\n",
    "            bear += -i\n",
    "#     return bull-bear\n",
    "    if bull == bear:\n",
    "        return 0\n",
    "    elif bull > bear:\n",
    "        return ((2*bull)/(bull+bear) - 1) / len(arr)\n",
    "    else:\n",
    "        return (1 - (2*bear)/(bull+bear)) / len(arr)\n",
    "\n",
    "data = df.groupby('date').agg({'sentiment': getIndex})['sentiment']\n",
    "data.to_csv('aggregate_tweet.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add time series to sentiment\n",
    "import datetime as dt\n",
    "df = pd.read_csv(\"./AAPL_data.csv\", usecols=[0,1,2,3,4,5])\n",
    "df['date'] = df['date'].map(lambda x: dt.datetime.strptime(x,\"%Y-%m-%d\").strftime('%Y.%m.%d'))\n",
    "\n",
    "data = pd.read_csv('./aggregate_tweet.csv', header=None, names = ['date', 'sentiment'])\n",
    "data = data.set_index('date')\n",
    "df = df.set_index('date')\n",
    "result = pd.concat([data, df], axis=1, join='inner')\n",
    "result['change'] = df['close'] - df['open']\n",
    "result.to_csv('./merged_result.csv')\n",
    "result = pd.read_csv('./merged_result.csv', usecols=[1,5,6,7])\n",
    "result.head()\n",
    "\n",
    "result['output'] = result.close.shift(-1)\n",
    "\n",
    "result.dropna(inplace=True)\n",
    "result.reset_index(drop=True,inplace=True)\n",
    "try:\n",
    "    result = result.drop(columns=['date'])\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>change</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.761479</td>\n",
       "      <td>0.409413</td>\n",
       "      <td>0.529666</td>\n",
       "      <td>0.579368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.847330</td>\n",
       "      <td>0.749844</td>\n",
       "      <td>0.347511</td>\n",
       "      <td>0.443428</td>\n",
       "      <td>0.678926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.780347</td>\n",
       "      <td>0.749587</td>\n",
       "      <td>0.204156</td>\n",
       "      <td>0.568751</td>\n",
       "      <td>0.547805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.852223</td>\n",
       "      <td>0.732606</td>\n",
       "      <td>0.384999</td>\n",
       "      <td>0.334851</td>\n",
       "      <td>0.614765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.864434</td>\n",
       "      <td>0.722254</td>\n",
       "      <td>0.431087</td>\n",
       "      <td>0.497403</td>\n",
       "      <td>0.573786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment     close    volume    change    output\n",
       "0   0.000000  0.761479  0.409413  0.529666  0.579368\n",
       "1   0.847330  0.749844  0.347511  0.443428  0.678926\n",
       "2   0.780347  0.749587  0.204156  0.568751  0.547805\n",
       "3   0.852223  0.732606  0.384999  0.334851  0.614765\n",
       "4   0.864434  0.722254  0.431087  0.497403  0.573786"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocess dataframe\n",
    "up = 1\n",
    "down = -1\n",
    "def setLabel(row):\n",
    "    yesterday = row['close']\n",
    "    today = row['output']\n",
    "    \n",
    "    #change = today - yesterday\n",
    "#     return today\n",
    "    return today - yesterday\n",
    "    if yesterday < today:\n",
    "        return up\n",
    "    if today < yesterday:\n",
    "        return down\n",
    "    return 0\n",
    "\n",
    "result['output'] = result.apply(setLabel, axis=1) #soal\n",
    "\n",
    "def norm(a):\n",
    "    b = a - a.min()\n",
    "    return b / b.max()\n",
    "\n",
    "result['sentiment'] = norm(result['sentiment'])\n",
    "result['output'] = norm(result['output'])\n",
    "result['change'] = norm(result['change'])\n",
    "result['close'] /= result['close'].max()\n",
    "result['volume'] /= result['volume'].max()\n",
    "result.to_csv('./ML_cols.csv', encoding='utf-8')\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 8s - loss: 0.0548\n",
      "Epoch 2/30\n",
      " - 3s - loss: 0.0309\n",
      "Epoch 3/30\n",
      " - 3s - loss: 0.0321\n",
      "Epoch 4/30\n",
      " - 3s - loss: 0.0281\n",
      "Epoch 5/30\n",
      " - 3s - loss: 0.0281\n",
      "Epoch 6/30\n",
      " - 3s - loss: 0.0188\n",
      "Epoch 7/30\n",
      " - 3s - loss: 0.0268\n",
      "Epoch 8/30\n",
      " - 3s - loss: 0.0234\n",
      "Epoch 9/30\n",
      " - 4s - loss: 0.0210\n",
      "Epoch 10/30\n",
      " - 4s - loss: 0.0221\n",
      "Epoch 11/30\n",
      " - 4s - loss: 0.0205\n",
      "Epoch 12/30\n",
      " - 4s - loss: 0.0214\n",
      "Epoch 13/30\n",
      " - 4s - loss: 0.0188\n",
      "Epoch 14/30\n",
      " - 4s - loss: 0.0190\n",
      "Epoch 15/30\n",
      " - 4s - loss: 0.0222\n",
      "Epoch 16/30\n",
      " - 3s - loss: 0.0215\n",
      "Epoch 17/30\n",
      " - 4s - loss: 0.0176\n",
      "Epoch 18/30\n",
      " - 4s - loss: 0.0183\n",
      "Epoch 19/30\n",
      " - 4s - loss: 0.0194\n",
      "Epoch 20/30\n",
      " - 5s - loss: 0.0201\n",
      "Epoch 21/30\n",
      " - 5s - loss: 0.0182\n",
      "Epoch 22/30\n",
      " - 4s - loss: 0.0193\n",
      "Epoch 23/30\n",
      " - 4s - loss: 0.0200\n",
      "Epoch 24/30\n",
      " - 4s - loss: 0.0206\n",
      "Epoch 25/30\n",
      " - 4s - loss: 0.0182\n",
      "Epoch 26/30\n",
      " - 3s - loss: 0.0187\n",
      "Epoch 27/30\n",
      " - 3s - loss: 0.0202\n",
      "Epoch 28/30\n",
      " - 3s - loss: 0.0194\n",
      "Epoch 29/30\n",
      " - 3s - loss: 0.0168\n",
      "Epoch 30/30\n",
      " - 4s - loss: 0.0196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cf38f58518>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit model\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LeakyReLU\n",
    "from keras.layers import LSTM, Dropout, Activation\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def create_dataset1(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = []\n",
    "        for j in range(look_back):\n",
    "            a += dataset[i+j, :-1].tolist()\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, -1])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(look_back-1, len(dataset)):\n",
    "        a = []\n",
    "        for j in range(look_back):\n",
    "            a += dataset[i-j, :-1].tolist()\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i, -1])\n",
    "    return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "numpy.random.seed(7)\n",
    "\n",
    "dataframe = pd.read_csv('./ML_cols.csv', usecols=[1,2,3,4,5])\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "x_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "look_back = 2\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "\n",
    "# trainX = x_scaler.fit_transform(trainX)\n",
    "# trainY  = y_scaler.fit_transform(trainY.reshape(-1,1))\n",
    "# testX = x_scaler.transform(testX)\n",
    "# testY = y_scaler.transform(testY.reshape(-1,1))\n",
    "\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(input_shape=(4 * look_back, trainX.shape[2]), return_sequences=True, units=50))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "#model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=30, batch_size=1, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.12 RMSE\n",
      "\n",
      "0.67892647 0.6203965\n",
      "0.5478052 0.6196151\n",
      "0.61476463 0.6192994\n",
      "0.5737857 0.6209295\n",
      "0.98283684 0.6187185\n",
      "0.54161435 0.62017155\n",
      "0.6445639 0.61439764\n",
      "0.7576961 0.6219719\n",
      "0.6721982 0.61820567\n",
      "0.7707161 0.6177963\n",
      "0.815034 0.61889786\n",
      "0.73475665 0.61724913\n",
      "0.54184175 0.61279345\n",
      "0.76299846 0.61830723\n",
      "0.80813175 0.6201404\n",
      "0.6614212 0.6183326\n",
      "0.7487795 0.6179949\n",
      "0.7051129 0.6185205\n",
      "0.7196996 0.61790705\n",
      "0.76028764 0.6186055\n",
      "0.6564791 0.6178532\n",
      "0.5021078 0.616778\n",
      "0.4524821 0.61874664\n",
      "0.7007516 0.6199395\n",
      "0.64141214 0.6201685\n",
      "0.75115144 0.6194309\n",
      "0.7437887 0.62035215\n",
      "0.658672 0.6176226\n",
      "0.82839406 0.61849964\n",
      "0.847597 0.61913073\n",
      "0.95513767 0.61488163\n",
      "0.6869317 0.61455613\n",
      "0.90811497 0.61481464\n",
      "0.69363004 0.6165501\n",
      "0.6738591 0.6121253\n",
      "0.684631 0.61717355\n",
      "0.72573876 0.617201\n",
      "0.6013743 0.6175517\n",
      "0.613533 0.61625385\n",
      "0.5723605 0.6189774\n",
      "0.6951423 0.6193963\n",
      "0.5897839 0.6186137\n",
      "0.6114612 0.61701787\n",
      "0.68146753 0.6197145\n",
      "0.61613554 0.61966413\n",
      "0.6742192 0.6190071\n",
      "0.62215525 0.6197245\n",
      "0.6445267 0.616897\n",
      "0.60547477 0.61874557\n",
      "0.61747915 0.6181767\n",
      "0.61122894 0.6182507\n",
      "0.7484927 0.61877394\n",
      "0.6757747 0.6182556\n",
      "0.6660799 0.6163789\n",
      "0.6331909 0.61792946\n",
      "0.59053904 0.6181147\n",
      "0.5506833 0.6179927\n",
      "0.60081124 0.6187688\n",
      "0.6538384 0.6176951\n",
      "0.56119436 0.6186924\n",
      "0.623797 0.61800647\n",
      "0.55395067 0.6196939\n",
      "0.62405616 0.6189487\n",
      "0.52494985 0.61684674\n",
      "0.6666052 0.61773396\n",
      "0.60116583 0.6174396\n",
      "0.6219458 0.6184337\n",
      "0.5494491 0.6198176\n",
      "0.728756 0.61904764\n",
      "0.63492817 0.61893666\n",
      "0.6902349 0.6171925\n",
      "0.62685513 0.61911434\n",
      "0.7112782 0.6177901\n",
      "0.5237395 0.6190236\n",
      "0.6958625 0.6164087\n",
      "0.7270506 0.6222131\n",
      "0.71871865 0.6187688\n",
      "0.6131206 0.6165172\n",
      "0.5384483 0.61760986\n",
      "0.73726976 0.6192677\n",
      "0.6292988 0.61916363\n",
      "0.60388863 0.61718047\n",
      "0.63784313 0.61899006\n",
      "0.5821923 0.6193812\n",
      "0.67146426 0.6175251\n",
      "0.6011457 0.6195663\n",
      "0.6233711 0.6164752\n",
      "0.6638724 0.6184815\n",
      "0.67314285 0.6181632\n",
      "0.5843402 0.61797285\n",
      "0.4982861 0.61728287\n",
      "0.58328944 0.61907405\n",
      "0.6362121 0.62160325\n",
      "1.0 0.62009597\n",
      "0.7783873 0.6169987\n",
      "0.5778174 0.61294925\n",
      "0.59174657 0.6104071\n",
      "0.48516145 0.6164813\n",
      "0.5633627 0.6172044\n",
      "0.61307764 0.6195466\n",
      "0.5309948 0.61704075\n",
      "0.5996659 0.6165881\n",
      "0.5790324 0.61777824\n",
      "0.5625112 0.6168946\n",
      "0.64830786 0.6183319\n",
      "0.67660284 0.6165973\n",
      "0.44459927 0.6158871\n",
      "0.5101429 0.6139566\n",
      "0.5262811 0.6196114\n",
      "0.5407912 0.6189827\n",
      "0.54691577 0.61719346\n",
      "0.5819462 0.61741376\n",
      "0.57454497 0.6184548\n",
      "0.6193326 0.6172528\n",
      "0.5653161 0.6169323\n",
      "0.57617986 0.614902\n",
      "0.5030772 0.61454844\n",
      "0.42519143 0.6154412\n",
      "0.35366297 0.61747634\n",
      "0.43457225 0.61887574\n",
      "0.40178415 0.61946416\n",
      "0.700312 0.617398\n",
      "0.39857414 0.6183491\n",
      "0.68387073 0.6125118\n",
      "0.39600915 0.6189146\n",
      "0.29099947 0.6142976\n",
      "0.52739555 0.6188787\n",
      "0.5182484 0.620264\n",
      "0.569538 0.61691403\n",
      "0.42688304 0.6176386\n",
      "0.62196356 0.61757004\n",
      "0.5515921 0.61547565\n",
      "0.43902957 0.61412275\n",
      "0.65891147 0.6157081\n",
      "0.515234 0.6179408\n",
      "0.5369507 0.6162493\n",
      "0.5481294 0.61694527\n",
      "0.5665537 0.6177974\n",
      "0.32352564 0.61558163\n",
      "0.35179815 0.61566323\n",
      "0.4733977 0.6195301\n",
      "0.59786224 0.61985886\n",
      "0.12557419 0.61573815\n",
      "acc:  None\n",
      "\n",
      "\n",
      "\n",
      "Test Score: 0.21 RMSE\n",
      "\n",
      "0.7873895 0.6239785\n",
      "0.33848384 0.6159073\n",
      "0.6792756 0.6155162\n",
      "0.46658877 0.62013257\n",
      "0.3277481 0.6148213\n",
      "0.6335766 0.6187924\n",
      "0.55515313 0.61865723\n",
      "0.57513505 0.616089\n",
      "0.23833922 0.6160673\n",
      "0.6851459 0.61190057\n",
      "0.38951087 0.6226645\n",
      "0.3837863 0.61559045\n",
      "0.5723953 0.61647516\n",
      "0.72066873 0.6219307\n",
      "0.625213 0.61518717\n",
      "0.0 0.61488414\n",
      "0.35518375 0.6130594\n",
      "0.6505328 0.61552334\n",
      "0.7776599 0.61747587\n",
      "0.5203833 0.615703\n",
      "0.41142616 0.6142391\n",
      "0.21340588 0.61895025\n",
      "0.53635573 0.61850834\n",
      "0.42519453 0.62027204\n",
      "0.7867306 0.6167419\n",
      "0.68469375 0.6214764\n",
      "0.34419745 0.6142248\n",
      "0.33218825 0.61519784\n",
      "0.6606209 0.62054896\n",
      "0.51569533 0.61715865\n",
      "0.7643195 0.62071216\n",
      "0.6634564 0.6207398\n",
      "0.9053266 0.6167128\n",
      "0.6051953 0.61497533\n",
      "0.62472826 0.6139219\n",
      "acc:  None\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "trainCorrect = trainY\n",
    "testCorrect = testY\n",
    "# trainPredict = y_scaler.inverse_transform(trainPredict)\n",
    "# trainCorrect = y_scaler.inverse_transform(trainY)\n",
    "# testPredict = y_scaler.inverse_transform(testPredict)\n",
    "# testCorrect = y_scaler.inverse_transform(testY)\n",
    "import math\n",
    "\n",
    "def sign(a):\n",
    "    if a>0:\n",
    "        return 1\n",
    "    if a<0:\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "def acc(a, b):\n",
    "    cnt = 0\n",
    "    for i in range(len(a)):\n",
    "        print(a[i], b[i])\n",
    "        if sign(a[i]) == sign(b[i]):\n",
    "            cnt += 1\n",
    "    return\n",
    "    return cnt / len(a)\n",
    "\n",
    "trainScore = math.sqrt(mean_squared_error(trainCorrect[:], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "print()\n",
    "print(\"acc: \", acc((trainCorrect[:]), (trainPredict[:,0])))\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "testScore = math.sqrt(mean_squared_error(testCorrect[:], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "print()\n",
    "print(\"acc: \", acc((testCorrect[:]), (testPredict[:,0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
